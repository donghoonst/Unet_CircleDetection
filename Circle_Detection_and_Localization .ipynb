{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 원 검출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_path = \"\" # 이미지 데이터 위치 넣기\n",
        "# load_images_and_contours -> opencv로 구성했었음(보안상의 이유로 삭제)\n",
        "train_images, train_contours = load_images_and_contours(train_path)\n",
        "\n",
        "# 첫 번째 이미지와 컨투어 시각화\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Resized Image\")\n",
        "plt.imshow(train_images[1].squeeze(), cmap='gray')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Contour Image\")\n",
        "plt.imshow(train_contours[1].squeeze(), cmap='gray')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 이미지 데이터를 읽고 contour를 추출하는 함수\n",
        "def load_images_and_contours(train_path):\n",
        "    images = []\n",
        "    contours = []\n",
        "\n",
        "    for filename in os.listdir(train_path):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # 이미지 파일 필터\n",
        "            img_path = os.path.join(train_path, filename)\n",
        "            \n",
        "            # 이미지 불러오기\n",
        "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            image_resized = cv2.resize(image, (128, 128))  # 필요한 크기로 리사이징\n",
        "            images.append(image_resized)\n",
        "\n",
        "            # 이진화 및 contour 추출\n",
        "            _, thresholded = cv2.threshold(image_resized, 220, 255, cv2.THRESH_BINARY)\n",
        "            contour_img = np.zeros_like(image_resized)\n",
        "            contours_detected, _ = cv2.findContours(thresholded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cv2.drawContours(contour_img, contours_detected, -1, (255, 255, 255), 1)\n",
        "            contours.append(contour_img)\n",
        "\n",
        "    return np.array(images), np.array(contours)\n",
        "\n",
        "train_path = \"\"\n",
        "\n",
        "# 이미지 및 컨투어 데이터 불러오기\n",
        "train_images, train_contours = load_images_and_contours(train_path)\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "train_contours = train_contours / 255.0\n",
        "\n",
        "\n",
        "# 데이터 차원 확장 (CNN 입력 형식에 맞게)\n",
        "train_images = train_images[..., np.newaxis]  # (num_samples, height, width, 1)\n",
        "train_contours = train_contours[..., np.newaxis]\n",
        "\n",
        "# 데이터를 train/validation 세트로 분할\n",
        "train_images, val_images, train_contours, val_contours = train_test_split(\n",
        "    train_images, train_contours, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def unet_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # 다운샘플링\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    # 병목 (Bottleneck)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "\n",
        "    # 업샘플링\n",
        "    u5 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c4)\n",
        "    u5 = layers.concatenate([u5, c3])\n",
        "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u5)\n",
        "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    u6 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c2])\n",
        "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c1])\n",
        "    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "# 모델 생성\n",
        "input_shape = (128, 128, 1)  # 흑백 이미지의 경우\n",
        "model = unet_model(input_shape)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(train_images, train_contours, epochs=100, batch_size=2, validation_data=(val_images, val_contours))\n",
        "\n",
        "# 훈련 및 검증 손실 시각화\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# 손실 그래프\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# 정확도 그래프\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 이미지 불러오기\n",
        "test_image_path = \"\"\n",
        "\n",
        "test_image = cv2.imread(test_image_path, cv2.IMREAD_GRAYSCALE)\n",
        "test_image = cv2.resize(test_image, (128,128))\n",
        "\n",
        "_, test_threshold = cv2.threshold(test_image, 220, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "test_image_resized = test_threshold\n",
        "\n",
        "\n",
        "# 모델 입력에 맞게 차원 추가\n",
        "test_image_resized = test_image_resized[..., np.newaxis]\n",
        "test_image_resized = np.expand_dims(test_image_resized, axis=0)  # 배치 차원 추가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# UNET 인공지능 활용\n",
        "result = model.predict(test_image_resized)\n",
        "\n",
        "plt.imshow(result[0,:,:,0],cmap='gray')\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result[0, :, :, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 흑백 이미지를 3채널 이미지로 변환\n",
        "original_image = cv2.cvtColor(test_image, cv2.COLOR_GRAY2BGR)\n",
        "original_image = cv2.resize(original_image, (128, 128))\n",
        "\n",
        "# UNET 모델 예측 결과를 이진 마스크로 변환\n",
        "mask = (result[0, :, :, 0] > 0.1).astype(np.uint8)  # 0.5를 기준으로 이진화\n",
        "\n",
        "# 빨간색 채널 생성 (빨간색으로 표시)\n",
        "red_overlay = np.zeros_like(original_image)\n",
        "red_overlay[:, :, 2] = mask * 255  # 빨간색 채널(BGR 중 R에 해당하는 2번 채널)만 마스크 적용\n",
        "\n",
        "# 원본 이미지에 빨간색 덮어씌우기\n",
        "overlayed_image = cv2.addWeighted(original_image, 1, red_overlay, 0.5, 0)\n",
        "\n",
        "# 이미지 출력\n",
        "plt.imshow(cv2.cvtColor(overlayed_image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#태스트 데이터 opencv활용 contour 검출\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Contour Image\")\n",
        "plt.imshow(test_image_resized[0,:,:,0], cmap='gray')\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Contour Image\")\n",
        "REAL_contour_img = np.zeros_like(test_image_resized[0,:,:,0])\n",
        "_, REAL_thresholded = cv2.threshold(test_image_resized[0,:,:,0], 150, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "REAL_contours_detected, _ = cv2.findContours(REAL_thresholded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "cv2.drawContours(REAL_contour_img, REAL_contours_detected, -1, (255, 255, 255), 1)\n",
        "plt.imshow(REAL_contour_img, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 이미지 불러오기\n",
        "Area_image = predicted_contours[0, :, :, 0]\n",
        "\n",
        "\n",
        "# 이진화된 이미지에서 하얀색 픽셀(값이 255인 픽셀)의 개수 세기\n",
        "white_pixel_count = np.sum(Area_image == 255)\n",
        "\n",
        "# 전체 픽셀 수 계산\n",
        "total_pixel_count = Area_image.size\n",
        "\n",
        "# 하얀색 면적 비율 계산\n",
        "white_area_ratio = white_pixel_count / total_pixel_count\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"하얀색 픽셀의 개수: {white_pixel_count}\")\n",
        "print(f\"전체 픽셀 수: {total_pixel_count}\")\n",
        "print(f\"하얀색 면적 비율: {white_area_ratio * 100:.2f}%\")\n",
        "\n",
        "# 이미지 시각화\n",
        "plt.imshow(Area_image, cmap='gray')\n",
        "plt.title(\"Binary Image\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNBNIaIYSTFyYBG6P722YlG",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Circle Detection and Localization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "working_hanyang",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
